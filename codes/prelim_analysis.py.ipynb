{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sincere donors=  115\n",
      "Sincere non-donors=  185\n"
     ]
    }
   ],
   "source": [
    "# import sys; sys.path.append('common/');\n",
    "from helper import *\n",
    "\n",
    "DATA_PATH = '/projects/persuasionforgood-master/Face_acts/dialogue_act_prediction/resisting-persuasion/data'\n",
    "\n",
    "df = pd.read_csv(DATA_PATH+'/Final_annotations.csv')\n",
    "df = df.rename(columns={\"Our Label\": \"fine_labels\"})\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['B4']==1 and row['fine_labels']!= row['fine_labels']:\n",
    "        print(index, row)\n",
    "\n",
    "\n",
    "fine_labels = [i for i in list(set(df['fine_labels'])) if i==i]\n",
    "\n",
    "fine2coarse_dict = {}\n",
    "fine2coarse_dict['deflect-responsibility'] = 'contesting'\n",
    "fine2coarse_dict['organization-inquiry']   = 'contesting'#'biased-processing'\n",
    "fine2coarse_dict['attack-credibility']     = 'contesting'\n",
    "fine2coarse_dict['self-pity']              = 'empowerment'\n",
    "fine2coarse_dict['nitpicking']             = 'contesting'\n",
    "fine2coarse_dict['direct-rejection']       = 'avoidance'\n",
    "fine2coarse_dict['personal-choice']        = 'empowerment'\n",
    "fine2coarse_dict['delay-tactic']           = 'avoidance'\n",
    "fine2coarse_dict['hesitance']              = 'avoidance'\n",
    "fine2coarse_dict['not-a-strategy']         = 'not-a-strategy'\n",
    "\n",
    "fine2resistance_dict = {}\n",
    "fine2resistance_dict['deflect-responsibility'] = 'counter-argumentation'\n",
    "fine2resistance_dict['organization-inquiry']   = 'information-inquiry' # biased-processing\n",
    "fine2resistance_dict['attack-credibility']     = 'source-degradation'\n",
    "fine2resistance_dict['self-pity']              = 'self-pity'\n",
    "fine2resistance_dict['nitpicking']             = 'counter-argumentation'\n",
    "fine2resistance_dict['direct-rejection']       = 'self-assertion'\n",
    "fine2resistance_dict['personal-choice']        = 'personal-choice'\n",
    "fine2resistance_dict['delay-tactic']           = 'selective-avoidance'\n",
    "fine2resistance_dict['hesitance']              = 'selective-avoidance'\n",
    "fine2resistance_dict['not-a-strategy']         = 'not-a-strategy'\n",
    "\n",
    "coarse_labels     = []\n",
    "resistance_labels = []\n",
    "\n",
    "df['fine_labels'] = df['fine_labels'].fillna('not-a-strategy')\n",
    "for i, row in df.iterrows():\n",
    "    label = row['fine_labels']\n",
    "    if label in fine2coarse_dict:\n",
    "        coarse_labels.append(fine2coarse_dict[label])\n",
    "        resistance_labels.append(fine2resistance_dict[label])\n",
    "    else:\n",
    "        resistance_labels.append('not-a-strategy')\n",
    "        coarse_labels.append('not-a-strategy')\n",
    "        \n",
    "df['coarse_labels'] = coarse_labels\n",
    "df['resistance_labels'] = resistance_labels\n",
    "\n",
    "df.to_csv(DATA_PATH+'/data.csv')\n",
    "info_df = pd.read_csv(DATA_PATH+'/300_info.csv',sep=',')\n",
    "\n",
    "sincere_donors_ids=set()\n",
    "sincere_nondonors_ids=set()\n",
    "for index, row in info_df.iterrows():\n",
    "    did= row['B2']\n",
    "    role=str(row['B4'])\n",
    "    prop_amt=float(row['B5'])\n",
    "    amt= float(row['B6'])\n",
    "    if role =='1':\n",
    "        if amt>0 and prop_amt<= amt:\n",
    "            sincere_donors_ids.add(did)\n",
    "        elif amt==0 and (prop_amt== 0 or math.isnan(prop_amt)):\n",
    "            sincere_nondonors_ids.add(did)\n",
    "        elif amt>0 and prop_amt> amt:\n",
    "            sincere_donors_ids.add(did)\n",
    "        else:\n",
    "            # print(amt,prop_amt)\n",
    "#             sincere_donors_ids.add(did)\n",
    "            sincere_nondonors_ids.add(did)\n",
    "\n",
    "print(\"Sincere donors= \",len(sincere_donors_ids))\n",
    "print(\"Sincere non-donors= \",len(sincere_nondonors_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohen_d(x,y):\n",
    "    nx = len(x)\n",
    "    ny = len(y)\n",
    "    dof = nx + ny - 2\n",
    "    return (np.mean(x) - np.mean(y)) / np.sqrt(((nx-1)*np.std(x, ddof=1) ** 2 + (ny-1)*np.std(y, ddof=1) ** 2) / dof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of valid data-points 4638\n"
     ]
    }
   ],
   "source": [
    "print('No of valid data-points {}'.format(len(df[df.B4==1])))\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "def group_name_dict(id_):\n",
    "    if id_ in sincere_donors_ids:\n",
    "        return 'SD'\n",
    "    elif id_ in sincere_nondonors_ids:\n",
    "        return 'SND'\n",
    "\n",
    "def print_label_dist(label_name):\n",
    "    labels_list  = list(set(list(df[df.B4==1][label_name])))\n",
    "    labels_dict  = ddict(lambda: ddict(int))\n",
    "    convs_dict   = ddict(lambda: ddict(list))\n",
    "        \n",
    "    df2 = df[df.B4 ==1]\n",
    "    curr_id = list(df2['B2'])[0]\n",
    "    temp_labels_dict = ddict(int)\n",
    "    \n",
    "    for index, row in df2.iterrows():\n",
    "        if curr_id != row['B2']:\n",
    "            group_name = group_name_dict(curr_id)\n",
    "            sum_labels_list = np.sum([temp_labels_dict[i] for i in temp_labels_dict])\n",
    "            for label in labels_list:\n",
    "                if label in temp_labels_dict:\n",
    "                    convs_dict[group_name][label].append(temp_labels_dict[label]/sum_labels_list)\n",
    "                else:\n",
    "                    convs_dict[group_name][label].append(0)\n",
    "            curr_id = row['B2']\n",
    "            temp_labels_dict = ddict(int)\n",
    "        temp_labels_dict[row[label_name]]+=1\n",
    "        labels_dict[group_name_dict(row['B2'])][row[label_name]]+=1\n",
    "    \n",
    "    # meant for the last index which would have been missed otherwise\n",
    "    group_name = group_name_dict(curr_id)\n",
    "    sum_labels_list = np.sum([temp_labels_dict[i] for i in temp_labels_dict])\n",
    "    for label in labels_list:\n",
    "        if label in temp_labels_dict:\n",
    "            convs_dict[group_name][label].append(temp_labels_dict[label]/sum_labels_list)\n",
    "        else:\n",
    "            convs_dict[group_name][label].append(0)\n",
    "\n",
    "    print('Distribution of the different strategies among the different categories')\n",
    "    print(\"Label,#Donor,#NonDonor,Mean-D,Mean-ND,pval-1,pval-2,Cohen-d\")\n",
    "\n",
    "#     print(\"Label\\t\\t\\t#Donor #NonDonor Mean-D Mean-ND pval-1\\t pval-2\\t Cohen-d\")\n",
    "    for label in labels_list:\n",
    "        a = convs_dict['SD'][label]\n",
    "        b = convs_dict['SND'][label]\n",
    "        mu_a = round(np.mean(a),3)\n",
    "        mu_b = round(np.mean(b),3)\n",
    "        sum_a = labels_dict['SD'][label]\n",
    "        sum_b = labels_dict['SND'][label]\n",
    "        stat, pval   = scipy.stats.ks_2samp(a,b)\n",
    "        stat2,pval2  = scipy.stats.ttest_ind(a,b,equal_var=False)\n",
    "        effect_size  = round(cohen_d(a,b),4)\n",
    "#         if len(label)<=len('personal-choice'):\n",
    "#             print(\"{}\\,\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\".format(label, sum_a, sum_b, mu_a , mu_b, round(pval,4), round(pval2,4), effect_size))\n",
    "#         else:\n",
    "#             print(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\".format(label, sum_a, sum_b, mu_a , mu_b, round(pval,4), round(pval2,4), effect_size))\n",
    "        print(\"{},{},{},{},{},{},{},{}\".format(label, sum_a, sum_b, mu_a , mu_b, round(pval,4), round(pval2,4), effect_size))\n",
    "    print('*********************************\\n\\n')\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of the different strategies among the different categories\n",
      "Label,#Donor,#NonDonor,Mean-D,Mean-ND,pval-1,pval-2,Cohen-d\n",
      "direct-rejection,6,45,0.004,0.015,0.2749,0.007,-0.2925\n",
      "not-a-strategy,1482,2017,0.799,0.717,0.0011,0.0012,0.3851\n",
      "deflect-responsibility,38,73,0.021,0.028,0.9732,0.2926,-0.1199\n",
      "organization-inquiry,137,322,0.088,0.117,0.0072,0.0763,-0.2145\n",
      "personal-choice,42,104,0.023,0.036,0.907,0.0662,-0.2026\n",
      "attack-credibility,44,100,0.025,0.033,0.5991,0.3106,-0.1186\n",
      "hesitance,9,26,0.004,0.01,0.991,0.0557,-0.2001\n",
      "nitpicking,13,30,0.008,0.009,1.0,0.9187,-0.0121\n",
      "delay-tactic,16,40,0.011,0.014,0.3727,0.5072,-0.0844\n",
      "self-pity,31,63,0.017,0.022,0.8089,0.4917,-0.0871\n",
      "*********************************\n",
      "\n",
      "\n",
      "Distribution of the different strategies among the different categories\n",
      "Label,#Donor,#NonDonor,Mean-D,Mean-ND,pval-1,pval-2,Cohen-d\n",
      "contesting,232,525,0.142,0.186,0.0461,0.0343,-0.2518\n",
      "not-a-strategy,1482,2017,0.799,0.717,0.0011,0.0012,0.3851\n",
      "empowerment,73,167,0.04,0.057,0.3727,0.0942,-0.1993\n",
      "avoidance,31,111,0.019,0.04,0.0028,0.0036,-0.3373\n",
      "*********************************\n",
      "\n",
      "\n",
      "Distribution of the different strategies among the different categories\n",
      "Label,#Donor,#NonDonor,Mean-D,Mean-ND,pval-1,pval-2,Cohen-d\n",
      "not-a-strategy,1482,2017,0.799,0.717,0.0011,0.0012,0.3851\n",
      "source-degradation,44,100,0.025,0.033,0.5991,0.3106,-0.1186\n",
      "personal-choice,42,104,0.023,0.036,0.907,0.0662,-0.2026\n",
      "self-assertion,6,45,0.004,0.015,0.2749,0.007,-0.2925\n",
      "information-inquiry,137,322,0.088,0.117,0.0072,0.0763,-0.2145\n",
      "selective-avoidance,25,66,0.015,0.024,0.1251,0.1057,-0.1905\n",
      "counter-argumentation,51,103,0.029,0.037,0.9514,0.3338,-0.1095\n",
      "self-pity,31,63,0.017,0.022,0.8089,0.4917,-0.0871\n",
      "*********************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_label_dist('fine_labels')\n",
    "\n",
    "print_label_dist('coarse_labels')\n",
    "\n",
    "print_label_dist('resistance_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'direct-rejection': 0, 'not-a-strategy': 1, 'deflect-responsibility': 2, 'organization-inquiry': 3, 'personal-choice': 4, 'attack-credibility': 5, 'hesitance': 6, 'nitpicking': 7, 'delay-tactic': 8, 'self-pity': 9})\n",
      "defaultdict(<class 'int'>, {'contesting': 0, 'not-a-strategy': 1, 'empowerment': 2, 'avoidance': 3})\n",
      "defaultdict(<class 'int'>, {'not-a-strategy': 0, 'source-degradation': 1, 'personal-choice': 2, 'self-assertion': 3, 'information-inquiry': 4, 'selective-avoidance': 5, 'counter-argumentation': 6, 'self-pity': 7})\n"
     ]
    }
   ],
   "source": [
    "fine_labels_dict = ddict(int)\n",
    "coarse_labels_dict = ddict(int)\n",
    "resistance_labels_dict = ddict(int)\n",
    "\n",
    "fine_labels_list = [i for i in list(set(df['fine_labels'])) if i==i]\n",
    "coarse_labels_list = [i for i in list(set(df['coarse_labels'])) if i!='None']\n",
    "resistance_labels_list = [i for i in list(set(df['resistance_labels'])) if i!='None' ]\n",
    "\n",
    "for i, elem in enumerate(fine_labels_list):\n",
    "    fine_labels_dict[elem]=i\n",
    "for i, elem in enumerate(coarse_labels_list):\n",
    "    coarse_labels_dict[elem]=i\n",
    "for i, elem in enumerate(resistance_labels_list):\n",
    "    resistance_labels_dict[elem]=i\n",
    "\n",
    "# {'nitpicking': 0, 'direct-rejection': 1, 'personal-choice': 2, 'self-pity': 3, 'attack-credibility': 4, 'organization-inquiry': 5, 'hesitance': 6, 'deflect-responsibility': 7, 'delay-tactic': 8, 'not-a-strategy': 9}\n",
    "\n",
    "print(fine_labels_dict)\n",
    "print(coarse_labels_dict)\n",
    "print(resistance_labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ds= list(set(sincere_donors_ids))\n",
    "NDs = list(set(sincere_nondonors_ids))\n",
    "alls = list(set(df['B2']))\n",
    "test_ids_dict = ddict(list)\n",
    "train_ids_dict = ddict(list)\n",
    "\n",
    "for count in range(0,5):\n",
    "    test_ids = [id_ for elem, id_ in enumerate(Ds) if elem%5 ==count]\n",
    "    test_ids.extend([id_ for elem, id_ in enumerate(NDs) if elem%5 ==count])\n",
    "    train_ids = [id_ for id_ in alls if id_ not in test_ids]\n",
    "    random.shuffle(test_ids)\n",
    "    random.shuffle(train_ids)\n",
    "    train_ids_dict[count] = train_ids\n",
    "    test_ids_dict[count]  = test_ids\n",
    "    \n",
    "\n",
    "info_dict = {}\n",
    "info_dict['fine_labels'] = fine_labels_dict\n",
    "info_dict['coarse_labels'] = coarse_labels_dict\n",
    "info_dict['resistance_labels'] = resistance_labels_dict\n",
    "info_dict['train_ids'] = train_ids_dict\n",
    "info_dict['test_ids']  = test_ids_dict\n",
    "\n",
    "with open(DATA_PATH+'info_dict.pt','rb') as handle:\n",
    "    info_dict= pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count 4\r"
     ]
    }
   ],
   "source": [
    "def process_cnn_text(text):\n",
    "    return text.replace('\\t',' ').lower().strip()\n",
    "\n",
    "\n",
    "for count in range(0,5):\n",
    "    print('count {}'.format(count), end ='\\r')\n",
    "    train_ids = train_ids_dict[count]\n",
    "    test_ids  = test_ids_dict[count]\n",
    "    \n",
    "    train= df.loc[(df['B2'].isin(train_ids)) & (df['B4']==1)]\n",
    "    test= df.loc[(df['B2'].isin(test_ids)) & (df['B4']==1)]\n",
    "    \n",
    "    coarse_train_csv = open(DATA_PATH+'/train/coarse_train'+str(count)+'.txt','w')\n",
    "    coarse_test_csv = open(DATA_PATH+'/test/coarse_test'+str(count)+'.txt','w')\n",
    "    \n",
    "    for index, row in train.iterrows():\n",
    "        coarse_train_csv.write(process_cnn_text(row['Unit'])+'\\t'+ str(info_dict['coarse_labels'][row['coarse_labels']])+'\\n')\n",
    "        \n",
    "    for index, row in test.iterrows():\n",
    "        coarse_test_csv.write(process_cnn_text(row['Unit'])+'\\t'+ str(info_dict['coarse_labels'][row['coarse_labels']])+'\\n')\n",
    "        \n",
    "    coarse_train_csv.close()\n",
    "    coarse_test_csv.close()\n",
    "        \n",
    "    fine_train_csv = open(DATA_PATH+'/train/fine_train'+str(count)+'.txt','w')\n",
    "    fine_test_csv = open(DATA_PATH+'/test/fine_test'+str(count)+'.txt','w')\n",
    "    \n",
    "    for index, row in train.iterrows():\n",
    "        fine_train_csv.write(process_cnn_text(row['Unit'])+'\\t'+ str(info_dict['fine_labels'][row['fine_labels']])+'\\n')\n",
    "        \n",
    "    for index, row in test.iterrows():\n",
    "        fine_test_csv.write(process_cnn_text(row['Unit'])+'\\t'+ str(info_dict['fine_labels'][row['fine_labels']])+'\\n')\n",
    "\n",
    "    fine_train_csv.close()\n",
    "    fine_test_csv.close()\n",
    "        \n",
    "    resistance_train_csv = open(DATA_PATH+'/train/resistance_train'+str(count)+'.txt','w')\n",
    "    resistance_test_csv = open(DATA_PATH+'/test/resistance_test'+str(count)+'.txt','w')\n",
    "    \n",
    "    for index, row in train.iterrows():\n",
    "        resistance_train_csv.write(process_cnn_text(row['Unit'])+'\\t'+ str(info_dict['resistance_labels'][row['resistance_labels']])+'\\n')\n",
    "        \n",
    "    for index, row in test.iterrows():\n",
    "        resistance_test_csv.write(process_cnn_text(row['Unit'])+'\\t'+ str(info_dict['resistance_labels'][row['resistance_labels']])+'\\n')\n",
    "\n",
    "    resistance_train_csv.close()\n",
    "    resistance_test_csv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B2</th>\n",
       "      <th>B4</th>\n",
       "      <th>Turn</th>\n",
       "      <th>Unit</th>\n",
       "      <th>er_label_1</th>\n",
       "      <th>ee_label_1</th>\n",
       "      <th>fine_labels</th>\n",
       "      <th>coarse_labels</th>\n",
       "      <th>resistance_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10387</th>\n",
       "      <td>20180827-050740_909_live</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>That really wouldn't bother me at all.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>negative-reaction-to-donation</td>\n",
       "      <td>personal-choice</td>\n",
       "      <td>empowerment</td>\n",
       "      <td>personal-choice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10388</th>\n",
       "      <td>20180827-050740_909_live</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>well like I said, any donation is a good donat...</td>\n",
       "      <td>logical-appeal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not-a-strategy</td>\n",
       "      <td>not-a-strategy</td>\n",
       "      <td>not-a-strategy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10389</th>\n",
       "      <td>20180827-050740_909_live</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>thank you for donating</td>\n",
       "      <td>thank</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not-a-strategy</td>\n",
       "      <td>not-a-strategy</td>\n",
       "      <td>not-a-strategy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10390</th>\n",
       "      <td>20180827-050740_909_live</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>I'm not donating to your children's charity.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>disagree-donation</td>\n",
       "      <td>direct-rejection</td>\n",
       "      <td>avoidance</td>\n",
       "      <td>self-assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10391</th>\n",
       "      <td>20180827-050740_909_live</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>How much are you donating?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ask-persuader-donation-intention</td>\n",
       "      <td>deflect-responsibility</td>\n",
       "      <td>contesting</td>\n",
       "      <td>counter-argumentation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             B2  B4  Turn  \\\n",
       "10387  20180827-050740_909_live   1     8   \n",
       "10388  20180827-050740_909_live   0     9   \n",
       "10389  20180827-050740_909_live   0     9   \n",
       "10390  20180827-050740_909_live   1     9   \n",
       "10391  20180827-050740_909_live   1     9   \n",
       "\n",
       "                                                    Unit      er_label_1  \\\n",
       "10387             That really wouldn't bother me at all.             NaN   \n",
       "10388  well like I said, any donation is a good donat...  logical-appeal   \n",
       "10389                             thank you for donating           thank   \n",
       "10390       I'm not donating to your children's charity.             NaN   \n",
       "10391                         How much are you donating?             NaN   \n",
       "\n",
       "                             ee_label_1             fine_labels  \\\n",
       "10387     negative-reaction-to-donation         personal-choice   \n",
       "10388                               NaN          not-a-strategy   \n",
       "10389                               NaN          not-a-strategy   \n",
       "10390                 disagree-donation        direct-rejection   \n",
       "10391  ask-persuader-donation-intention  deflect-responsibility   \n",
       "\n",
       "        coarse_labels      resistance_labels  \n",
       "10387     empowerment        personal-choice  \n",
       "10388  not-a-strategy         not-a-strategy  \n",
       "10389  not-a-strategy         not-a-strategy  \n",
       "10390       avoidance         self-assertion  \n",
       "10391      contesting  counter-argumentation  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, importlib\n",
    "importlib.reload(sys.modules['helper'])\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create data jsons for the Hi-GRU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>score</th>\n",
       "      <th>AffectDimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>outraged</td>\n",
       "      <td>0.964</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brutality</td>\n",
       "      <td>0.959</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hatred</td>\n",
       "      <td>0.953</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hateful</td>\n",
       "      <td>0.940</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>terrorize</td>\n",
       "      <td>0.939</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        term  score AffectDimension\n",
       "0   outraged  0.964           anger\n",
       "1  brutality  0.959           anger\n",
       "2     hatred  0.953           anger\n",
       "3    hateful  0.940           anger\n",
       "4  terrorize  0.939           anger"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sadness', 'fear', 'anger', 'joy'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Arousal</th>\n",
       "      <th>Dominance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aaaaaaah</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaaah</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aardvark</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aback</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abacus</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word  Valence  Arousal  Dominance\n",
       "0  aaaaaaah    0.479    0.606      0.291\n",
       "1     aaaah    0.520    0.636      0.282\n",
       "2  aardvark    0.427    0.490      0.437\n",
       "3     aback    0.385    0.407      0.288\n",
       "4    abacus    0.510    0.276      0.485"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Presence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aback</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aback</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aback</td>\n",
       "      <td>disgust</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aback</td>\n",
       "      <td>fear</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aback</td>\n",
       "      <td>joy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Word       Emotion  Presence\n",
       "0  aback         anger         0\n",
       "1  aback  anticipation         0\n",
       "2  aback       disgust         0\n",
       "3  aback          fear         0\n",
       "4  aback           joy         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'positive', 'disgust', 'negative', 'trust', 'fear', 'anger', 'sadness', 'surprise', 'anticipation', 'joy'}\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "affect_file= '../data/Resources/NRC_affect.txt'\n",
    "affect_df= pd.read_csv(affect_file, sep='\\t', lineterminator='\\n')\n",
    "display(affect_df.head())\n",
    "\n",
    "print(set(affect_df['AffectDimension']))\n",
    "\n",
    "vad_file= '../data/Resources/NRC_vad.txt'\n",
    "vad_df= pd.read_csv(vad_file, sep='\\t', lineterminator='\\n')\n",
    "\n",
    "display(vad_df.head())\n",
    "\n",
    "emotion_file= '../data/Resources/NRC_emotion.txt'\n",
    "emo_df= pd.read_csv(emotion_file, sep='\\t', lineterminator='\\n')\n",
    "display(emo_df.head())\n",
    "print(set(emo_df['Emotion']))\n",
    "\n",
    "with open('../data/Resources/word_categories.p','rb') as handle:\n",
    "    word_categories_dict= pickle.load(handle)\n",
    "\n",
    "with open('../data/Resources/starred_word_categories.p','rb')as handle:\n",
    "    starred_word_categories_dict= pickle.load(handle)\n",
    "\n",
    "liwc_categories=['Funct','Pronoun','Ppron','I','We','You','SheHe','They','Ipron','Article','Verbs','AuxVb','Past','Present','Future','Adverbs','Prep','Conj','Negate','Quant','Numbers','Swear','','Family','Friends','Humans','Affect','Posemo','Negemo','Anx','Anger','Sad','CogMech','Insight','Cause','Discrep','Tentat','Certain','Inhib','Incl','Excl','Percept','See','Hear','Feel','Body','Health','Sexual','Ingest','Relativ','Motion','Space','Time','Work','Achiev','Leisure','Home','Money','Relig','Death','Assent','Nonflu','Filler','Other']\t\n",
    "\n",
    "print(len(liwc_categories))\n",
    "\n",
    "def create_vad_dict(vad_df):\n",
    "    vad_dict={}\n",
    "    for index, row in vad_df.iterrows():\n",
    "        w= row['Word']\n",
    "        vad_dict[w]={}\n",
    "        vad_dict[w]['Valence']=row['Valence']\n",
    "        vad_dict[w]['Arousal']= row['Arousal']\n",
    "        vad_dict[w]['Dominance']= row['Dominance']\n",
    "    \n",
    "    return vad_dict\n",
    "\n",
    "def create_emo_dict(emo_df):\n",
    "    emo_dict={}\n",
    "    emotions_set=list({'trust', 'fear', 'surprise', 'sadness', 'positive', 'joy', 'anger', 'negative', 'disgust', 'anticipation'})\n",
    "    for index, row in emo_df.iterrows():\n",
    "        w= row['Word']\n",
    "        if w not in emo_dict:\n",
    "            emo_dict[w]={}\n",
    "            for emotion in emotions_set:\n",
    "                emo_dict[w][emotion]=0\n",
    "        emo_dict[w][row['Emotion']]= row['Presence']\n",
    "    \n",
    "    return emo_dict\n",
    "\n",
    "def create_affect_dict(affect_df):\n",
    "    affect_dict={}\n",
    "    affect_set= list({'joy', 'sadness', 'fear', 'anger'})\n",
    "    for index, row in affect_df.iterrows():\n",
    "        w= row['term']\n",
    "        if w not in affect_dict:\n",
    "            affect_dict[w]={}\n",
    "            for affect in affect_set:\n",
    "                affect_dict[w][affect]=0\n",
    "        affect_dict[w][row['AffectDimension']]= row['score']\n",
    "    return affect_dict\n",
    "\n",
    "vad_dict= create_vad_dict(vad_df)\n",
    "emo_dict= create_emo_dict(emo_df)\n",
    "affect_dict= create_affect_dict(affect_df)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def create_embeddings(word_list, vads, affects, emos):\n",
    "    \n",
    "    vad_sent_dict={}\n",
    "    affect_sent_dict={}\n",
    "    emo_sent_dict={}\n",
    "    \n",
    "    for elem in vads:\n",
    "        vad_sent_dict[elem]=[]\n",
    "    for elem in affects:\n",
    "        affect_sent_dict[elem]=[]\n",
    "    for elem in emos:\n",
    "        emo_sent_dict[elem]=[]\n",
    "    \n",
    "    for w in word_list:\n",
    "        if w in vad_dict:\n",
    "            for elem in vads:\n",
    "                try:\n",
    "                    vad_sent_dict[elem].append(float(vad_dict[w][elem]))\n",
    "                except Exception as e:\n",
    "                    vad_sent_dict[elem].append(0)\n",
    "        else:\n",
    "            for elem in vads:\n",
    "                vad_sent_dict[elem].append(0)\n",
    "        \n",
    "        if w in affect_dict:\n",
    "            for elem in affects:\n",
    "                try:\n",
    "                    affect_sent_dict[elem].append(float(affect_dict[w][elem]))\n",
    "                except Exception as e:\n",
    "                    affect_sent_dict[elem].append(0)\n",
    "        else:\n",
    "            for elem in affects:\n",
    "                affect_sent_dict[elem].append(0)\n",
    "        \n",
    "        if w in emo_dict:\n",
    "            for elem in emos:\n",
    "                try:\n",
    "                    emo_sent_dict[elem].append(float(emo_dict[w][elem]))\n",
    "                except Exception as e:\n",
    "                    emo_sent_dict[elem].append(0)\n",
    "        else:\n",
    "            for elem in emos:\n",
    "                emo_sent_dict[elem].append(0)\n",
    "            \n",
    "    vad_features    = []\n",
    "    affect_features = []\n",
    "    emo_features    = []\n",
    "    \n",
    "    for elem in vads:\n",
    "        val = np.mean(vad_sent_dict[elem])\n",
    "        if val== val:\n",
    "            vad_features.append(val)\n",
    "        else:\n",
    "            vad_features.append(0)\n",
    "            \n",
    "    for elem in affects:\n",
    "        val = np.mean(affect_sent_dict[elem])\n",
    "        if val== val:\n",
    "            affect_features.append(val)\n",
    "        else:\n",
    "            affect_features.append(0)\n",
    "    for elem in emos:\n",
    "        val = np.mean(emo_sent_dict[elem])\n",
    "        if val== val:\n",
    "            emo_features.append(val)\n",
    "        else:\n",
    "            emo_features.append(0)\n",
    "        \n",
    "    return vad_features, affect_features, emo_features\n",
    "\n",
    "def create_liwc(words):\n",
    "    category_tag={}\n",
    "    count=0\n",
    "    for category in liwc_categories:\n",
    "        category_tag[category]=0\n",
    "    category_tag['Other']=0\t\n",
    "\n",
    "    for word in words:\n",
    "        flag1=0\n",
    "        flag2=0\n",
    "\n",
    "        if word_categories_dict[word]!=[]:\n",
    "            flag1=1\n",
    "\n",
    "        for category in word_categories_dict[word]:\n",
    "            if category not in category_tag:\n",
    "                category_tag[category]=1\n",
    "            else:\n",
    "                category_tag[category]+=1\n",
    "\n",
    "        for substring in starred_word_categories_dict.keys():\n",
    "            if word.startswith(substring):\n",
    "                flag2=1\n",
    "                for category in starred_word_categories_dict[substring]:\n",
    "                    if category not in category_tag:\n",
    "                        category_tag[category]=1\n",
    "                    else:\n",
    "                        category_tag[category]+=1\n",
    "\n",
    "        if flag1==0 and flag2==0:\n",
    "            category_tag['Other']+=1\n",
    "        count+=1\n",
    "\n",
    "    if count>0:\n",
    "        for i in category_tag:\n",
    "            category_tag[i]=category_tag[i]/count\n",
    "\n",
    "    return category_tag\n",
    "\n",
    "vads=['Valence', 'Arousal', 'Dominance']\n",
    "affects=sorted(list({'joy', 'sadness', 'fear', 'anger'}))\n",
    "emos=sorted(list({'trust', 'fear', 'surprise', 'sadness', 'positive', 'joy', 'anger', 'negative', 'disgust', 'anticipation'}))\n",
    "liwc_categories=['Funct','Pronoun','Ppron','I','We','You','SheHe','They','Ipron','Article','Verbs','AuxVb','Past','Present','Future','Adverbs','Prep','Conj','Negate','Quant','Numbers','Swear','','Family','Friends','Humans','Affect','Posemo','Negemo','Anx','Anger','Sad','CogMech','Insight','Cause','Discrep','Tentat','Certain','Inhib','Incl','Excl','Percept','See','Hear','Feel','Body','Health','Sexual','Ingest','Relativ','Motion','Space','Time','Work','Achiev','Leisure','Home','Money','Relig','Death','Assent','Nonflu','Filler','Other']\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive-reaction-to-donation', 'task-related-inquiry', 'acknowledgement', 'greeting', 'agree-donation', 'disagree-donation', 'negative-to-inquiry', 'closing', 'you-are-welcome', 'provide-donation-amount', 'neutral-reaction-to-donation', 'personal-related-inquiry', 'disagree-donation-more', 'thank', 'positive-to-inquiry', 'negative-reaction-to-donation', 'ask-donation-procedure', 'ask-org-info', 'neutral-to-inquiry', 'off-task', 'confirm-donation', 'ask-persuader-donation-intention', 'other']\n",
      "['ask-not-donate-reason', 'greeting', 'acknowledgement', 'negative-to-inquiry', 'closing', 'you-are-welcome', 'thank', 'positive-to-inquiry', 'ask-donation-amount', 'proposition-of-donation', 'neutral-to-inquiry', 'praise-user', 'off-task', 'confirm-donation', 'ask-donate-more', 'other', 'comment-partner']\n",
      "['logical-appeal', 'credibility-appeal', 'self-modeling', 'foot-in-the-door', 'source-related-inquiry', 'emotion-appeal', 'personal-related-inquiry', 'donation-information', 'task-related-inquiry', 'personal-story']\n"
     ]
    }
   ],
   "source": [
    "face_act_dir = '/projects/persuasionforgood-master/Face_acts/data/'\n",
    "\n",
    "df1 = pd.read_csv(face_act_dir+'train0.csv')\n",
    "df2 = pd.read_csv(face_act_dir+'test0.csv')\n",
    "df3 = pd.concat([df1,df2])\n",
    "\n",
    "face_acts  = ['spos+','spos-','sneg+','hpos+','hpos-','hneg+','hneg-','other']\n",
    "sentiments = ['pos','neg','neu']\n",
    "er_strategies  = [\"logical-appeal\",\"credibility-appeal\",\"self-modeling\",\"foot-in-the-door\",\"source-related-inquiry\",\"emotion-appeal\",\"personal-related-inquiry\",\"donation-information\",\"task-related-inquiry\",\"personal-story\"]\n",
    "er_DAs     = [i for i in list(set(list(df['er_label_1']))) if i==i and i not in er_strategies]\n",
    "ee_DAs     = list(set([i for i in list(set(list(df['ee_label_1']))) if i ==i]))\n",
    "\n",
    "print(ee_DAs)\n",
    "print(er_DAs)\n",
    "print(er_strategies)\n",
    "\n",
    "df3.to_csv('../data/face_act.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'20180723-025150_733_live', '20180826-174120_426_live', '20180825-210735_192_live', '20180808-013755_350_live', '20180825-060251_387_live', '20180808-011921_673_live', '20180825-075630_493_live', '20180808-052501_689_live', '20180826-062755_702_live', '20180827-033451_673_live', '20180825-070900_49_live', '20180826-054028_444_live', '20180719-211253_768_live', '20180826-174957_757_live', '20180826-180631_700_live', '20180825-081402_621_live', '20180825-044048_639_live', '20180826-082717_200_live', '20180903-103939_512_live', '20180827-032731_796_live', '20180826-181951_904_live', '20180723-061928_535_live', '20180825-080802_964_live', '20180723-052203_936_live', '20180808-034352_717_live', '20180903-163331_887_live', '20180904-024226_703_live', '20180723-114415_254_live', '20180825-071727_819_live', '20180904-025026_901_live', '20180826-184037_209_live', '20180826-212714_597_live', '20180825-063117_677_live', '20180826-182522_887_live', '20180825-053711_81_live', '20180717-200206_41_live', '20180825-083745_516_live', '20180825-060648_863_live', '20180723-055038_776_live', '20180808-033451_555_live', '20180827-033412_606_live', '20180825-062128_451_live', '20180723-073908_711_live', '20180902-215344_542_live', '20180826-054232_684_live', '20180723-073352_280_live', '20180902-220100_244_live', '20180723-113700_19_live', '20180825-075844_569_live', '20180827-034916_910_live', '20180825-055427_625_live', '20180808-070517_921_live', '20180828-151914_101_live', '20180904-032932_423_live', '20180902-222227_892_live', '20180827-025236_792_live', '20180808-015530_429_live', '20180825-143255_249_live', '20180825-064001_264_live', '20180826-013529_897_live', '20180825-081859_875_live', '20180825-084254_215_live', '20180826-072151_442_live', '20180826-040651_411_live', '20180904-012448_306_live', '20180719-202443_897_live', '20180824-031232_169_live', '20180827-004200_630_live', '20180826-203821_83_live', '20180825-080436_824_live', '20180825-064811_939_live', '20180825-125810_869_live', '20180827-043632_426_live', '20180827-041028_432_live', '20180827-032811_159_live', '20180825-061105_792_live', '20180825-044613_233_live', '20180826-175426_937_live', '20180826-070022_438_live', '20180826-073858_133_live', '20180827-021816_456_live', '20180723-040634_575_live', '20180808-011341_389_live', '20180826-021724_326_live', '20180723-101530_805_live', '20180825-042845_49_live', '20180723-112016_503_live', '20180723-031022_254_live', '20180826-052222_969_live', '20180825-043341_782_live', '20180825-075451_984_live', '20180826-210609_644_live', '20180829-082113_449_live', '20180825-075611_866_live', '20180826-175853_545_live', '20180825-054948_621_live', '20180723-093509_578_live', '20180825-055321_232_live', '20180825-065411_526_live', '20180826-220528_999_live', '20180825-065106_23_live', '20180825-102556_172_live', '20180825-051212_932_live', '20180825-071459_643_live', '20180826-013831_953_live', '20180826-204907_535_live', '20180904-004818_580_live', '20180825-044252_786_live', '20180825-085709_930_live', '20180903-111245_955_live', '20180723-034109_263_live', '20180825-074318_984_live', '20180719-122534_38_live', '20180825-080131_220_live', '20180824-020419_695_live'}\n"
     ]
    }
   ],
   "source": [
    "print(sincere_donors_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "only_words = r'\\b\\w+\\b'\n",
    "\n",
    "exception_arr = []\n",
    "\n",
    "def normalize_arr(arr):\n",
    "    if np.sum(arr)>0:\n",
    "        return arr/np.sum(arr)\n",
    "    else:\n",
    "        return np.zeros(len(arr))\n",
    "\n",
    "def create_conv(temp_df, train_flag = True):\n",
    "    try:\n",
    "        curr_id      = list(temp_df['B2'])[0]\n",
    "    except Exception as e:\n",
    "        import pdb; pdb.set_trace()\n",
    "    \n",
    "\n",
    "    convs      = []\n",
    "    conv       = []\n",
    "    max_utt_len  = 0\n",
    "    er_strategies_feats = np.zeros(len(er_strategies))\n",
    "    er_DAs_feats        = np.zeros(len(er_DAs))\n",
    "    ee_DAs_feats        = np.zeros(len(ee_DAs))\n",
    "    \n",
    "    print(temp_df.columns)\n",
    "\n",
    "    max_utt_len = 0 \n",
    "    for index, row in temp_df.iterrows():\n",
    "        print('Done for {}'.format(index), end='\\r')\n",
    "        if row['B2']!= curr_id:\n",
    "            for elem in conv:\n",
    "                elem['bert-feat'].extend([0 for i in range(max_utt_len-len(elem['bert-feat']))])\n",
    "            if conv != []:\n",
    "                convs.append(conv)\n",
    "            conv = []\n",
    "            max_utt_len =0\n",
    "            curr_id = row['B2']\n",
    "            er_strategies_feats = np.zeros(len(er_strategies))\n",
    "            er_DAs_feats        = np.zeros(len(er_DAs))\n",
    "            ee_DAs_feats        = np.zeros(len(ee_DAs))\n",
    "\n",
    "        utt_dict = {}\n",
    "        text_df = df3[(df3['B2']==row['B2'])& (df3['Turn']==row['Turn'])& (df3['B4']==row['B4'])]\n",
    "        row_sent = str(row['Unit']).replace(' ','').strip()\n",
    "        \n",
    "        for index, row2 in text_df.iterrows():\n",
    "            df3_sent = str(row2['Unit']).replace(' ','').strip()\n",
    "            if row_sent == df3_sent:\n",
    "        \n",
    "                utt_dict['utterance'] = row2['Unit']\n",
    "                utt = normalizeString(row2['Unit'])\n",
    "                toks = tokenizer.convert_tokens_to_ids(tokenizer.tokenize('[CLS]')) +  tokenizer.convert_tokens_to_ids(tokenizer.tokenize(utt)) + tokenizer.convert_tokens_to_ids(tokenizer.tokenize('[SEP]'))\n",
    "                max_utt_len = max(max_utt_len, len(toks))\n",
    "                utt_dict['bert-feat'] = toks\n",
    "                utt_dict['fine_labels'] = row['fine_labels']\n",
    "                utt_dict['coarse_labels']= row['coarse_labels']\n",
    "                utt_dict['resistance_labels']= row['resistance_labels']\n",
    "                utt_dict['speaker']= row['B4']\n",
    "\n",
    "                word_list= re.findall(only_words, row2['Unit'].lower().strip())\n",
    "                vad_feats, affect_feats, emo_feats = create_embeddings(word_list, vads, affects, emos)\n",
    "                \n",
    "                for elem in vad_feats:\n",
    "                    if elem!=elem:\n",
    "                        import pdb; pdb.set_trace()\n",
    "                \n",
    "                liwc_feats= create_liwc(word_list)\n",
    "\n",
    "                utt_dict['vad_features'] = vad_feats\n",
    "                utt_dict['affect_features'] = affect_feats\n",
    "                utt_dict['emo_features'] = emo_feats\n",
    "                utt_dict['liwc_features'] = [liwc_feats[i] for i in liwc_categories]\n",
    "\n",
    "                utt_dict['sentiments'] = [row2['pos'], row2['neg'],row2['neu']]\n",
    "                \n",
    "                utt_dict['face_acts']  = []\n",
    "        \n",
    "                for fact in face_acts:\n",
    "                    utt_dict['face_acts'].append(row2[fact])\n",
    "\n",
    "                if row['B4'] == 0:\n",
    "                    if row['er_label_1'] in er_strategies:\n",
    "                        er_index = er_strategies.index(row['er_label_1'])\n",
    "                        er_strategies_feats[er_index]+=1\n",
    "\n",
    "                    else:\n",
    "                        er_index = er_DAs.index(row['er_label_1'])\n",
    "                        er_DAs_feats[er_index]+=1\n",
    "                else:           \n",
    "                    ee_index = ee_DAs.index(row['ee_label_1'])\n",
    "                    ee_DAs_feats[ee_index]+=1\n",
    "\n",
    "                utt_dict['er_strategies']      = list(er_strategies_feats)\n",
    "                utt_dict['norm_er_strategies'] = list(normalize_arr(er_strategies_feats))\n",
    "                utt_dict['er_DAs']             = list(er_DAs_feats)\n",
    "                utt_dict['norm_er_DAs']        = list(normalize_arr(er_DAs_feats))\n",
    "                utt_dict['ee_DAs']             = list(ee_DAs_feats)\n",
    "                utt_dict['norm_ee_DAs']        = list(normalize_arr(ee_DAs_feats))\n",
    "                if row['B2'] in sincere_donors_ids:\n",
    "                    utt_dict['donor'] = 1\n",
    "                else:\n",
    "                    utt_dict['donor'] = 0\n",
    "                conv.append(utt_dict)\n",
    "                break\n",
    "\n",
    "    for elem in conv:\n",
    "        elem['bert-feat'].extend([0 for i in range(max_utt_len-len(elem['bert-feat']))])\n",
    "        \n",
    "    if conv != []:\n",
    "        convs.append(conv)\n",
    "\n",
    "    print(len(convs))\n",
    "    \n",
    "    return convs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['B2', 'B4', 'Turn', 'Unit', 'er_label_1', 'ee_label_1', 'fine_labels',\n",
      "       'coarse_labels', 'resistance_labels'],\n",
      "      dtype='object')\n",
      "Done for 6464\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr0/home/rdutt/anaconda3/envs/med_ent/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr0/home/rdutt/anaconda3/envs/med_ent/lib/python3.6/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226e for 10391\n",
      "Index(['B2', 'B4', 'Turn', 'Unit', 'er_label_1', 'ee_label_1', 'fine_labels',\n",
      "       'coarse_labels', 'resistance_labels'],\n",
      "      dtype='object')\n",
      "58ne for 10208\n",
      "Index(['B2', 'B4', 'Turn', 'Unit', 'er_label_1', 'ee_label_1', 'fine_labels',\n",
      "       'coarse_labels', 'resistance_labels'],\n",
      "      dtype='object')\n",
      "227e for 10391\n",
      "Index(['B2', 'B4', 'Turn', 'Unit', 'er_label_1', 'ee_label_1', 'fine_labels',\n",
      "       'coarse_labels', 'resistance_labels'],\n",
      "      dtype='object')\n",
      "57ne for 10185\n",
      "Index(['B2', 'B4', 'Turn', 'Unit', 'er_label_1', 'ee_label_1', 'fine_labels',\n",
      "       'coarse_labels', 'resistance_labels'],\n",
      "      dtype='object')\n",
      "226e for 10350\n",
      "Index(['B2', 'B4', 'Turn', 'Unit', 'er_label_1', 'ee_label_1', 'fine_labels',\n",
      "       'coarse_labels', 'resistance_labels'],\n",
      "      dtype='object')\n",
      "58ne for 10391\n",
      "Index(['B2', 'B4', 'Turn', 'Unit', 'er_label_1', 'ee_label_1', 'fine_labels',\n",
      "       'coarse_labels', 'resistance_labels'],\n",
      "      dtype='object')\n",
      "225e for 10391\n",
      "Index(['B2', 'B4', 'Turn', 'Unit', 'er_label_1', 'ee_label_1', 'fine_labels',\n",
      "       'coarse_labels', 'resistance_labels'],\n",
      "      dtype='object')\n",
      "59ne for 10350\n",
      "Index(['B2', 'B4', 'Turn', 'Unit', 'er_label_1', 'ee_label_1', 'fine_labels',\n",
      "       'coarse_labels', 'resistance_labels'],\n",
      "      dtype='object')\n",
      "232e for 10391\n",
      "Index(['B2', 'B4', 'Turn', 'Unit', 'er_label_1', 'ee_label_1', 'fine_labels',\n",
      "       'coarse_labels', 'resistance_labels'],\n",
      "      dtype='object')\n",
      "52ne for 10267\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "train_ids_dict =  info_dict['train_ids']\n",
    "test_ids_dict  =  info_dict['test_ids']\n",
    "\n",
    "\n",
    "for count in range(0,5):\n",
    "    print('count {}'.format(count), end ='\\r')\n",
    "    train_ids = train_ids_dict[count]\n",
    "    test_ids  = test_ids_dict[count]\n",
    "    \n",
    "    train= df.loc[df['B2'].isin(train_ids)]\n",
    "    conv_json = create_conv(train, True)\n",
    "    with open(DATA_PATH+'/higru_bert_data/train'+str(count)+'.json','w') as handle:\n",
    "        json.dump(conv_json,handle, indent=4)\n",
    "    \n",
    "    test= df.loc[df['B2'].isin(test_ids)]\n",
    "    conv_json = create_conv(test, False)\n",
    "    with open(DATA_PATH+'/higru_bert_data/test'+str(count)+'.json','w') as handle:\n",
    "        json.dump(conv_json,handle, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count 0\r",
      "10 10 0\n",
      "count 1\r",
      "10 10 0\n",
      "count 2\r",
      "10 10 0\n",
      "count 3\r",
      "10 10 0\n",
      "count 4\r",
      "10 10 0\n"
     ]
    }
   ],
   "source": [
    "for count in range(0,5):\n",
    "    print('count {}'.format(count), end ='\\r')\n",
    "    train_ids = train_ids_dict[count]\n",
    "    test_ids  = test_ids_dict[count]\n",
    "    \n",
    "    train= df.loc[df['B2'].isin(train_ids)]\n",
    "    train_labels = set(train['fine_labels'])\n",
    "    \n",
    "    test= df.loc[df['B2'].isin(test_ids)]\n",
    "    test_labels = set(test['fine_labels'])\n",
    "    \n",
    "    print(len(train_labels), len(test_labels), len(test_labels - train_labels))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vad_features', 'affect_features', 'emo_features', 'liwc_features', 'sentiments', 'face_acts', 'norm_er_strategies', 'norm_er_DAs', 'ee_DAs']\n"
     ]
    }
   ],
   "source": [
    "feature_dim_dict = {'vad_features': 3, 'affect_features': 4, 'emo_features': 10, 'liwc_features': 64, 'sentiments': 3, 'face_acts': 8, 'norm_er_strategies': 10, 'norm_er_DAs': 17, 'ee_DAs': 23, 'all': 3+4+10+64+3+8+10+17+23}\n",
    "\n",
    "feature_dim_arr  = [i for i in feature_dim_dict if i!='all']\n",
    "print(feature_dim_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
