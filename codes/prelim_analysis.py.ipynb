{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sincere donors=  115\n",
      "Sincere non-donors=  185\n"
     ]
    }
   ],
   "source": [
    "import sys; sys.path.append('common/');\n",
    "from helper import *\n",
    "\n",
    "DATA_PATH = '/projects/persuasionforgood-master/Face_acts/dialogue_act_prediction/resisting-persuasion/data'\n",
    "\n",
    "df = pd.read_csv(DATA_PATH+'/Final_annotations.csv')\n",
    "df = df.rename(columns={\"Our Label\": \"fine_labels\"})\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['B4']==1 and row['fine_labels']!= row['fine_labels']:\n",
    "        print(index, row)\n",
    "\n",
    "\n",
    "fine_labels = [i for i in list(set(df['fine_labels'])) if i==i]\n",
    "\n",
    "fine2coarse_dict = {}\n",
    "fine2coarse_dict['deflect-responsibility'] = 'contesting'\n",
    "fine2coarse_dict['organization-inquiry']   = 'contesting'#'biased-processing'\n",
    "fine2coarse_dict['attack-credibility']     = 'contesting'\n",
    "fine2coarse_dict['self-pity']              = 'empowerment'\n",
    "fine2coarse_dict['nitpicking']             = 'contesting'\n",
    "fine2coarse_dict['direct-rejection']       = 'avoidance'\n",
    "fine2coarse_dict['personal-choice']        = 'empowerment'\n",
    "fine2coarse_dict['delay-tactic']           = 'avoidance'\n",
    "fine2coarse_dict['hesitance']              = 'avoidance'\n",
    "fine2coarse_dict['not-a-strategy']         = 'not-a-strategy'\n",
    "\n",
    "fine2resistance_dict = {}\n",
    "fine2resistance_dict['deflect-responsibility'] = 'counter-argumentation'\n",
    "fine2resistance_dict['organization-inquiry']   = 'source-degradation' # biased-processing\n",
    "fine2resistance_dict['attack-credibility']     = 'source-degradation'\n",
    "fine2resistance_dict['self-pity']              = 'empowerment'\n",
    "fine2resistance_dict['nitpicking']             = 'counter-argumentation'\n",
    "fine2resistance_dict['direct-rejection']       = 'self-assertion'\n",
    "fine2resistance_dict['personal-choice']        = 'attitude-bolstering'\n",
    "fine2resistance_dict['delay-tactic']           = 'avoidance'\n",
    "fine2resistance_dict['hesitance']              = 'avoidance'\n",
    "fine2resistance_dict['not-a-strategy']         = 'not-a-strategy'\n",
    "\n",
    "coarse_labels     = []\n",
    "resistance_labels = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    label = row['fine_labels']\n",
    "    if label in fine2coarse_dict:\n",
    "        coarse_labels.append(fine2coarse_dict[label])\n",
    "        resistance_labels.append(fine2resistance_dict[label])\n",
    "    else:\n",
    "        resistance_labels.append('None')\n",
    "        coarse_labels.append('None')\n",
    "        \n",
    "df['coarse_labels'] = coarse_labels\n",
    "df['resistance_labels'] = resistance_labels\n",
    "\n",
    "df.to_csv(DATA_PATH+'/data.csv')\n",
    "info_df = pd.read_csv(DATA_PATH+'/300_info.csv',sep=',')\n",
    "\n",
    "sincere_donors_ids=set()\n",
    "sincere_nondonors_ids=set()\n",
    "for index, row in info_df.iterrows():\n",
    "    did= row['B2']\n",
    "    role=str(row['B4'])\n",
    "    prop_amt=float(row['B5'])\n",
    "    amt= float(row['B6'])\n",
    "    if role =='1':\n",
    "        if amt>0 and prop_amt<= amt:\n",
    "            sincere_donors_ids.add(did)\n",
    "        elif amt==0 and (prop_amt== 0 or math.isnan(prop_amt)):\n",
    "            sincere_nondonors_ids.add(did)\n",
    "        elif amt>0 and prop_amt> amt:\n",
    "            sincere_donors_ids.add(did)\n",
    "        else:\n",
    "            # print(amt,prop_amt)\n",
    "#             sincere_donors_ids.add(did)\n",
    "            sincere_nondonors_ids.add(did)\n",
    "\n",
    "print(\"Sincere donors= \",len(sincere_donors_ids))\n",
    "print(\"Sincere non-donors= \",len(sincere_nondonors_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohen_d(x,y):\n",
    "    nx = len(x)\n",
    "    ny = len(y)\n",
    "    dof = nx + ny - 2\n",
    "    return (np.mean(x) - np.mean(y)) / np.sqrt(((nx-1)*np.std(x, ddof=1) ** 2 + (ny-1)*np.std(y, ddof=1) ** 2) / dof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of valid data-points 4638\n"
     ]
    }
   ],
   "source": [
    "print('No of valid data-points {}'.format(len(df[df.B4==1])))\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "def group_name_dict(id_):\n",
    "    if id_ in sincere_donors_ids:\n",
    "        return 'SD'\n",
    "    elif id_ in sincere_nondonors_ids:\n",
    "        return 'SND'\n",
    "\n",
    "def print_label_dist(label_name):\n",
    "    labels_list  = list(set(list(df[df.B4==1][label_name])))\n",
    "    labels_dict  = ddict(lambda: ddict(int))\n",
    "    convs_dict   = ddict(lambda: ddict(list))\n",
    "        \n",
    "    df2 = df[df.B4 ==1]\n",
    "    curr_id = list(df2['B2'])[0]\n",
    "    temp_labels_dict = ddict(int)\n",
    "    \n",
    "    for index, row in df2.iterrows():\n",
    "        if curr_id != row['B2']:\n",
    "            group_name = group_name_dict(curr_id)\n",
    "            sum_labels_list = np.sum([temp_labels_dict[i] for i in temp_labels_dict])\n",
    "            for label in labels_list:\n",
    "                if label in temp_labels_dict:\n",
    "                    convs_dict[group_name][label].append(temp_labels_dict[label]/sum_labels_list)\n",
    "                else:\n",
    "                    convs_dict[group_name][label].append(0)\n",
    "            curr_id = row['B2']\n",
    "            temp_labels_dict = ddict(int)\n",
    "        temp_labels_dict[row[label_name]]+=1\n",
    "        labels_dict[group_name_dict(row['B2'])][row[label_name]]+=1\n",
    "    \n",
    "    # meant for the last index which would have been missed otherwise\n",
    "    group_name = group_name_dict(curr_id)\n",
    "    sum_labels_list = np.sum([temp_labels_dict[i] for i in temp_labels_dict])\n",
    "    for label in labels_list:\n",
    "        if label in temp_labels_dict:\n",
    "            convs_dict[group_name][label].append(temp_labels_dict[label]/sum_labels_list)\n",
    "        else:\n",
    "            convs_dict[group_name][label].append(0)\n",
    "\n",
    "    print('Distribution of the different strategies among the different categories')\n",
    "    print(\"Label\\t\\t\\t#Donor #NonDonor Mean-D Mean-ND pval-1\\t pval-2\\t Cohen-d\")\n",
    "    for label in labels_list:\n",
    "        a = convs_dict['SD'][label]\n",
    "        b = convs_dict['SND'][label]\n",
    "        mu_a = round(np.mean(a),3)\n",
    "        mu_b = round(np.mean(b),3)\n",
    "        sum_a = labels_dict['SD'][label]\n",
    "        sum_b = labels_dict['SND'][label]\n",
    "        stat, pval   = scipy.stats.ks_2samp(a,b)\n",
    "        stat2,pval2  = scipy.stats.ttest_ind(a,b,equal_var=False)\n",
    "        effect_size  = round(cohen_d(a,b),4)\n",
    "        if len(label)<=len('personal-choice'):\n",
    "            print(\"{}\\t\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\".format(label, sum_a, sum_b, mu_a , mu_b, round(pval,4), round(pval2,4), effect_size))\n",
    "        else:\n",
    "            print(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\".format(label, sum_a, sum_b, mu_a , mu_b, round(pval,4), round(pval2,4), effect_size))\n",
    "    print('*********************************\\n\\n')\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of the different strategies among the different categories\n",
      "Label\t\t\t#Donor #NonDonor Mean-D Mean-ND pval-1\t pval-2\t Cohen-d\n",
      "not-a-strategy\t\t1482\t2017\t0.799\t0.717\t0.001\t0.0012\t0.3851\n",
      "direct-rejection\t6\t45\t0.004\t0.015\t0.2815\t0.007\t-0.2925\n",
      "delay-tactic\t\t16\t40\t0.011\t0.014\t0.3824\t0.5072\t-0.0844\n",
      "personal-choice\t\t42\t104\t0.023\t0.036\t0.9201\t0.0662\t-0.2026\n",
      "attack-credibility\t44\t100\t0.025\t0.033\t0.6147\t0.3106\t-0.1186\n",
      "hesitance\t\t9\t26\t0.004\t0.01\t0.994\t0.0557\t-0.2001\n",
      "deflect-responsibility\t38\t73\t0.021\t0.028\t0.9796\t0.2926\t-0.1199\n",
      "nitpicking\t\t13\t30\t0.008\t0.009\t1.0\t0.9187\t-0.0121\n",
      "organization-inquiry\t137\t322\t0.088\t0.117\t0.0071\t0.0763\t-0.2145\n",
      "self-pity\t\t31\t63\t0.017\t0.022\t0.8255\t0.4917\t-0.0871\n",
      "*********************************\n",
      "\n",
      "\n",
      "Distribution of the different strategies among the different categories\n",
      "Label\t\t\t#Donor #NonDonor Mean-D Mean-ND pval-1\t pval-2\t Cohen-d\n",
      "empowerment\t\t73\t167\t0.04\t0.057\t0.3824\t0.0942\t-0.1993\n",
      "avoidance\t\t31\t111\t0.019\t0.04\t0.0028\t0.0036\t-0.3373\n",
      "contesting\t\t232\t525\t0.142\t0.186\t0.0465\t0.0343\t-0.2518\n",
      "not-a-strategy\t\t1482\t2017\t0.799\t0.717\t0.001\t0.0012\t0.3851\n",
      "*********************************\n",
      "\n",
      "\n",
      "Distribution of the different strategies among the different categories\n",
      "Label\t\t\t#Donor #NonDonor Mean-D Mean-ND pval-1\t pval-2\t Cohen-d\n",
      "self-assertion\t\t6\t45\t0.004\t0.015\t0.2815\t0.007\t-0.2925\n",
      "attitude-bolstering\t42\t104\t0.023\t0.036\t0.9201\t0.0662\t-0.2026\n",
      "not-a-strategy\t\t1482\t2017\t0.799\t0.717\t0.001\t0.0012\t0.3851\n",
      "counter-argumentation\t51\t103\t0.029\t0.037\t0.9607\t0.3338\t-0.1095\n",
      "empowerment\t\t31\t63\t0.017\t0.022\t0.8255\t0.4917\t-0.0871\n",
      "source-degradation\t181\t422\t0.113\t0.149\t0.0078\t0.044\t-0.24\n",
      "avoidance\t\t25\t66\t0.015\t0.024\t0.1272\t0.1057\t-0.1905\n",
      "*********************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_label_dist('fine_labels')\n",
    "\n",
    "print_label_dist('coarse_labels')\n",
    "\n",
    "print_label_dist('resistance_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'not-a-strategy': 0, 'direct-rejection': 1, 'delay-tactic': 2, 'personal-choice': 3, 'attack-credibility': 4, 'hesitance': 5, 'deflect-responsibility': 6, 'nitpicking': 7, 'organization-inquiry': 8, 'self-pity': 9})\n",
      "defaultdict(<class 'int'>, {'contesting': 0, 'not-a-strategy': 1, 'empowerment': 2, 'avoidance': 3})\n",
      "defaultdict(<class 'int'>, {'self-assertion': 0, 'attitude-bolstering': 1, 'not-a-strategy': 2, 'counter-argumentation': 3, 'empowerment': 4, 'source-degradation': 5, 'avoidance': 6})\n"
     ]
    }
   ],
   "source": [
    "fine_labels_dict = ddict(int)\n",
    "coarse_labels_dict = ddict(int)\n",
    "resistance_labels_dict = ddict(int)\n",
    "\n",
    "fine_labels_list = [i for i in list(set(df['fine_labels'])) if i==i]\n",
    "coarse_labels_list = [i for i in list(set(df['coarse_labels'])) if i!='None']\n",
    "resistance_labels_list = [i for i in list(set(df['resistance_labels'])) if i!='None' ]\n",
    "\n",
    "for i, elem in enumerate(fine_labels_list):\n",
    "    fine_labels_dict[elem]=i\n",
    "for i, elem in enumerate(coarse_labels_list):\n",
    "    coarse_labels_dict[elem]=i\n",
    "for i, elem in enumerate(resistance_labels_list):\n",
    "    resistance_labels_dict[elem]=i\n",
    "\n",
    "# {'nitpicking': 0, 'direct-rejection': 1, 'personal-choice': 2, 'self-pity': 3, 'attack-credibility': 4, 'organization-inquiry': 5, 'hesitance': 6, 'deflect-responsibility': 7, 'delay-tactic': 8, 'not-a-strategy': 9}\n",
    "\n",
    "print(fine_labels_dict)\n",
    "print(coarse_labels_dict)\n",
    "print(resistance_labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ds= list(set(sincere_donors_ids))\n",
    "NDs = list(set(sincere_nondonors_ids))\n",
    "alls = list(set(df['B2']))\n",
    "test_ids_dict = ddict(list)\n",
    "train_ids_dict = ddict(list)\n",
    "\n",
    "for count in range(0,5):\n",
    "    test_ids = [id_ for elem, id_ in enumerate(Ds) if elem%5 ==count]\n",
    "    test_ids.extend([id_ for elem, id_ in enumerate(NDs) if elem%5 ==count])\n",
    "    train_ids = [id_ for id_ in alls if id_ not in test_ids]\n",
    "    random.shuffle(test_ids)\n",
    "    random.shuffle(train_ids)\n",
    "    train_ids_dict[count] = train_ids\n",
    "    test_ids_dict[count]  = test_ids\n",
    "    \n",
    "\n",
    "info_dict = {}\n",
    "info_dict['fine_labels'] = fine_labels_dict\n",
    "info_dict['coarse_labels'] = coarse_labels_dict\n",
    "info_dict['resistance_labels'] = resistance_labels_dict\n",
    "info_dict['train_ids'] = train_ids_dict\n",
    "info_dict['test_ids']  = test_ids_dict\n",
    "\n",
    "with open(DATA_PATH+'info_dict.pt','wb') as handle:\n",
    "    pickle.dump(info_dict, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 60), (1, 60), (2, 60), (3, 60), (4, 60)]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count 4\r"
     ]
    }
   ],
   "source": [
    "def process_cnn_text(text):\n",
    "    return text.replace('\\t',' ').lower().strip()\n",
    "\n",
    "\n",
    "for count in range(0,5):\n",
    "    print('count {}'.format(count), end ='\\r')\n",
    "    train_ids = train_ids_dict[count]\n",
    "    test_ids  = test_ids_dict[count]\n",
    "    \n",
    "    train= df.loc[df['B2'].isin(train_ids)]\n",
    "    test= df.loc[df['B2'].isin(test_ids)]\n",
    "    \n",
    "    coarse_train_csv = open(DATA_PATH+'/train/coarse_train'+str(count)+'.txt','w')\n",
    "    coarse_test_csv = open(DATA_PATH+'/test/coarse_test'+str(count)+'.txt','w')\n",
    "    \n",
    "    for index, row in train.iterrows():\n",
    "        coarse_train_csv.write(process_cnn_text(row['Unit'])+'\\t'+ str(info_dict['coarse_labels'][row['coarse_labels']])+'\\n')\n",
    "        \n",
    "    for index, row in test.iterrows():\n",
    "        coarse_test_csv.write(process_cnn_text(row['Unit'])+'\\t'+ str(info_dict['coarse_labels'][row['coarse_labels']])+'\\n')\n",
    "        \n",
    "    coarse_train_csv.close()\n",
    "    coarse_test_csv.close()\n",
    "        \n",
    "    fine_train_csv = open(DATA_PATH+'/train/fine_train'+str(count)+'.txt','w')\n",
    "    fine_test_csv = open(DATA_PATH+'/test/fine_test'+str(count)+'.txt','w')\n",
    "    \n",
    "    for index, row in train.iterrows():\n",
    "        fine_train_csv.write(process_cnn_text(row['Unit'])+'\\t'+ str(info_dict['fine_labels'][row['fine_labels']])+'\\n')\n",
    "        \n",
    "    for index, row in test.iterrows():\n",
    "        fine_test_csv.write(process_cnn_text(row['Unit'])+'\\t'+ str(info_dict['fine_labels'][row['fine_labels']])+'\\n')\n",
    "\n",
    "    fine_train_csv.close()\n",
    "    fine_test_csv.close()\n",
    "        \n",
    "    resistance_train_csv = open(DATA_PATH+'/train/resistance_train'+str(count)+'.txt','w')\n",
    "    resistance_test_csv = open(DATA_PATH+'/test/resistance_test'+str(count)+'.txt','w')\n",
    "    \n",
    "    for index, row in train.iterrows():\n",
    "        resistance_train_csv.write(process_cnn_text(row['Unit'])+'\\t'+ str(info_dict['resistance_labels'][row['resistance_labels']])+'\\n')\n",
    "        \n",
    "    for index, row in test.iterrows():\n",
    "        resistance_test_csv.write(process_cnn_text(row['Unit'])+'\\t'+ str(info_dict['resistance_labels'][row['resistance_labels']])+'\\n')\n",
    "\n",
    "    resistance_train_csv.close()\n",
    "    resistance_test_csv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
