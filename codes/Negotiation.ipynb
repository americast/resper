{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Index</th>\n",
       "      <th>User</th>\n",
       "      <th>Text</th>\n",
       "      <th>Resistance Labels</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>C_e2781ecd69264b00a4cc25ee96d271c5</td>\n",
       "      <td>1</td>\n",
       "      <td>Hello</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>C_e2781ecd69264b00a4cc25ee96d271c5</td>\n",
       "      <td>0</td>\n",
       "      <td>Hi there. I had a few questions about the phon...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>C_e2781ecd69264b00a4cc25ee96d271c5</td>\n",
       "      <td>1</td>\n",
       "      <td>Sure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>C_e2781ecd69264b00a4cc25ee96d271c5</td>\n",
       "      <td>0</td>\n",
       "      <td>How old is the phone? I don`t see it stated an...</td>\n",
       "      <td>Source Derogation-Contesting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>C_e2781ecd69264b00a4cc25ee96d271c5</td>\n",
       "      <td>1</td>\n",
       "      <td>2 years old</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                               Index  User  \\\n",
       "0          33  C_e2781ecd69264b00a4cc25ee96d271c5     1   \n",
       "1          34  C_e2781ecd69264b00a4cc25ee96d271c5     0   \n",
       "2          35  C_e2781ecd69264b00a4cc25ee96d271c5     1   \n",
       "3          36  C_e2781ecd69264b00a4cc25ee96d271c5     0   \n",
       "4          37  C_e2781ecd69264b00a4cc25ee96d271c5     1   \n",
       "\n",
       "                                                Text  \\\n",
       "0                                              Hello   \n",
       "1  Hi there. I had a few questions about the phon...   \n",
       "2                                               Sure   \n",
       "3  How old is the phone? I don`t see it stated an...   \n",
       "4                                        2 years old   \n",
       "\n",
       "              Resistance Labels Unnamed: 5 Unnamed: 6  \n",
       "0                           NaN        NaN        NaN  \n",
       "1                           NaN        NaN        NaN  \n",
       "2                           NaN        NaN        NaN  \n",
       "3  Source Derogation-Contesting        NaN        NaN  \n",
       "4                           NaN        NaN        NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "12373 879 703\n"
     ]
    }
   ],
   "source": [
    "# import sys; sys.path.append('common/');\n",
    "from helper import *\n",
    "import sys, importlib\n",
    "importlib.reload(sys.modules['helper'])\n",
    "from helper import *\n",
    "\n",
    "DATA_PATH = '/projects/persuasionforgood-master/Face_acts/dialogue_act_prediction/resisting-persuasion/data'\n",
    "\n",
    "df = pd.read_csv(DATA_PATH+'/neg_final_convs.csv')\n",
    "display(df.head())\n",
    "\n",
    "df = df.rename(columns={\"Resistance Labels\": \"fine_labels\"})\n",
    "\n",
    "valid_ids = []\n",
    "all_ids = list(set(list(df['Index'])))\n",
    "\n",
    "spam_text ='''C_2bdb308591df45e29a321a7cfd167002\n",
    "C_a7e41f175b6f4a53ab31daa0bb02de8b\n",
    "C_91995f19b3664f4dad37c6b738be5bf4\n",
    "C_e93957571b1140e48dffc52829252ed7\n",
    "C_d26bad533e364c4d9b8358d777ad3205\n",
    "C_399c1f48c33b4561aa7ce7652e953682\n",
    "C_7e57a726bcb045df8e2105da21341f9a\n",
    "C_c6a45e6e9d624babbf8b5cdc008f7f36\n",
    "C_9e3c0dea33da49a8bde97a19e62f3bf7\n",
    "C_6b1dae69c75941d39d021a4c38d1e3df\n",
    "C_1f50c4606e234f8f956bdf6356300ad6\n",
    "C_dc99d0923cf74332a0e4eb8f832da0a9\n",
    "C_13ac299de52c434a88565e0ec3f9f387\n",
    "C_78ef20d98c2143dfa452136cda053592\n",
    "C_38bfc703b8e04023b6379861fd1ae55f\n",
    "C_efe36c78d44c43d6947efab9a72c979e'''\n",
    "\n",
    "spam_ids = set(spam_text.split('\\n'))\n",
    "print(len(spam_ids))\n",
    "\n",
    "for id_ in all_ids:\n",
    "    temp_df = df[df['Index']==id_]\n",
    "    for index, row in temp_df.iterrows():\n",
    "        label = row['fine_labels']\n",
    "        if label ==label:\n",
    "            valid_ids.append(id_)\n",
    "            break\n",
    "\n",
    "valid_ids = list(set(valid_ids)-spam_ids)\n",
    "print(len(df), len(all_ids), len(set(valid_ids)))\n",
    "df = df.loc[(df['Index'].isin(valid_ids))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fine_labels'] = df['fine_labels'].fillna('not-a-strategy')\n",
    "df['resistance_labels'] = df['fine_labels']\n",
    "\n",
    "with open(DATA_PATH+'/neg.pkl','rb') as handle:\n",
    "    neg_pickle = pickle.load(handle)\n",
    "    \n",
    "\n",
    "conv_dict = {}\n",
    "for conv in neg_pickle['train']:\n",
    "    conv_dict[conv['uuid']] = conv\n",
    "for conv in neg_pickle['test']:\n",
    "    conv_dict[conv['uuid']] = conv\n",
    "for conv in neg_pickle['valid']:\n",
    "    conv_dict[conv['uuid']] = conv\n",
    "\n",
    "all_uuids = list([conv for conv in conv_dict])\n",
    "valid_ids = list(set(all_uuids)&set(valid_ids))\n",
    "random.shuffle(valid_ids)\n",
    "\n",
    "train_ids_dict = {}\n",
    "test_ids_dict  = {}\n",
    "\n",
    "random.shuffle(all_uuids)\n",
    "for count in range(0,5):\n",
    "    test_ids_dict[count]  = [valid_id for i, valid_id in enumerate(valid_ids) if i%5==count] \n",
    "    train_ids_dict[count] = [i for i in valid_ids if i not in test_ids_dict[count]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'not-a-strategy', 'Self Pity-Empowement', 'Counter Argumentation-Contesting', 'Hesitance-Hesitance', 'Self Assertion-Empowerment', 'Personal Choice-Empowerment', 'Source Derogation-Contesting', 'Information Inquiry-Contesting'}\n"
     ]
    }
   ],
   "source": [
    "print(set(df['resistance_labels']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create data jsons for the Hi-GRU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>score</th>\n",
       "      <th>AffectDimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>outraged</td>\n",
       "      <td>0.964</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brutality</td>\n",
       "      <td>0.959</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hatred</td>\n",
       "      <td>0.953</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hateful</td>\n",
       "      <td>0.940</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>terrorize</td>\n",
       "      <td>0.939</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        term  score AffectDimension\n",
       "0   outraged  0.964           anger\n",
       "1  brutality  0.959           anger\n",
       "2     hatred  0.953           anger\n",
       "3    hateful  0.940           anger\n",
       "4  terrorize  0.939           anger"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fear', 'anger', 'sadness', 'joy'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Arousal</th>\n",
       "      <th>Dominance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aaaaaaah</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaaah</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aardvark</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aback</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abacus</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word  Valence  Arousal  Dominance\n",
       "0  aaaaaaah    0.479    0.606      0.291\n",
       "1     aaaah    0.520    0.636      0.282\n",
       "2  aardvark    0.427    0.490      0.437\n",
       "3     aback    0.385    0.407      0.288\n",
       "4    abacus    0.510    0.276      0.485"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Presence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aback</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aback</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aback</td>\n",
       "      <td>disgust</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aback</td>\n",
       "      <td>fear</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aback</td>\n",
       "      <td>joy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Word       Emotion  Presence\n",
       "0  aback         anger         0\n",
       "1  aback  anticipation         0\n",
       "2  aback       disgust         0\n",
       "3  aback          fear         0\n",
       "4  aback           joy         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'positive', 'anticipation', 'sadness', 'surprise', 'negative', 'trust', 'fear', 'anger', 'disgust', 'joy'}\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "affect_file= '../data/Resources/NRC_affect.txt'\n",
    "affect_df= pd.read_csv(affect_file, sep='\\t', lineterminator='\\n')\n",
    "display(affect_df.head())\n",
    "\n",
    "print(set(affect_df['AffectDimension']))\n",
    "\n",
    "vad_file= '../data/Resources/NRC_vad.txt'\n",
    "vad_df= pd.read_csv(vad_file, sep='\\t', lineterminator='\\n')\n",
    "\n",
    "display(vad_df.head())\n",
    "\n",
    "emotion_file= '../data/Resources/NRC_emotion.txt'\n",
    "emo_df= pd.read_csv(emotion_file, sep='\\t', lineterminator='\\n')\n",
    "display(emo_df.head())\n",
    "print(set(emo_df['Emotion']))\n",
    "\n",
    "with open('../data/Resources/word_categories.p','rb') as handle:\n",
    "    word_categories_dict= pickle.load(handle)\n",
    "\n",
    "with open('../data/Resources/starred_word_categories.p','rb')as handle:\n",
    "    starred_word_categories_dict= pickle.load(handle)\n",
    "\n",
    "liwc_categories=['Funct','Pronoun','Ppron','I','We','You','SheHe','They','Ipron','Article','Verbs','AuxVb','Past','Present','Future','Adverbs','Prep','Conj','Negate','Quant','Numbers','Swear','','Family','Friends','Humans','Affect','Posemo','Negemo','Anx','Anger','Sad','CogMech','Insight','Cause','Discrep','Tentat','Certain','Inhib','Incl','Excl','Percept','See','Hear','Feel','Body','Health','Sexual','Ingest','Relativ','Motion','Space','Time','Work','Achiev','Leisure','Home','Money','Relig','Death','Assent','Nonflu','Filler','Other']\t\n",
    "\n",
    "print(len(liwc_categories))\n",
    "\n",
    "def create_vad_dict(vad_df):\n",
    "    vad_dict={}\n",
    "    for index, row in vad_df.iterrows():\n",
    "        w= row['Word']\n",
    "        vad_dict[w]={}\n",
    "        vad_dict[w]['Valence']=row['Valence']\n",
    "        vad_dict[w]['Arousal']= row['Arousal']\n",
    "        vad_dict[w]['Dominance']= row['Dominance']\n",
    "    \n",
    "    return vad_dict\n",
    "\n",
    "def create_emo_dict(emo_df):\n",
    "    emo_dict={}\n",
    "    emotions_set=list({'trust', 'fear', 'surprise', 'sadness', 'positive', 'joy', 'anger', 'negative', 'disgust', 'anticipation'})\n",
    "    for index, row in emo_df.iterrows():\n",
    "        w= row['Word']\n",
    "        if w not in emo_dict:\n",
    "            emo_dict[w]={}\n",
    "            for emotion in emotions_set:\n",
    "                emo_dict[w][emotion]=0\n",
    "        emo_dict[w][row['Emotion']]= row['Presence']\n",
    "    \n",
    "    return emo_dict\n",
    "\n",
    "def create_affect_dict(affect_df):\n",
    "    affect_dict={}\n",
    "    affect_set= list({'joy', 'sadness', 'fear', 'anger'})\n",
    "    for index, row in affect_df.iterrows():\n",
    "        w= row['term']\n",
    "        if w not in affect_dict:\n",
    "            affect_dict[w]={}\n",
    "            for affect in affect_set:\n",
    "                affect_dict[w][affect]=0\n",
    "        affect_dict[w][row['AffectDimension']]= row['score']\n",
    "    return affect_dict\n",
    "\n",
    "vad_dict= create_vad_dict(vad_df)\n",
    "emo_dict= create_emo_dict(emo_df)\n",
    "affect_dict= create_affect_dict(affect_df)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def create_embeddings(word_list, vads, affects, emos):\n",
    "    \n",
    "    vad_sent_dict={}\n",
    "    affect_sent_dict={}\n",
    "    emo_sent_dict={}\n",
    "    \n",
    "    for elem in vads:\n",
    "        vad_sent_dict[elem]=[]\n",
    "    for elem in affects:\n",
    "        affect_sent_dict[elem]=[]\n",
    "    for elem in emos:\n",
    "        emo_sent_dict[elem]=[]\n",
    "    \n",
    "    for w in word_list:\n",
    "        if w in vad_dict:\n",
    "            for elem in vads:\n",
    "                try:\n",
    "                    vad_sent_dict[elem].append(float(vad_dict[w][elem]))\n",
    "                except Exception as e:\n",
    "                    vad_sent_dict[elem].append(0)\n",
    "        else:\n",
    "            for elem in vads:\n",
    "                vad_sent_dict[elem].append(0)\n",
    "        \n",
    "        if w in affect_dict:\n",
    "            for elem in affects:\n",
    "                try:\n",
    "                    affect_sent_dict[elem].append(float(affect_dict[w][elem]))\n",
    "                except Exception as e:\n",
    "                    affect_sent_dict[elem].append(0)\n",
    "        else:\n",
    "            for elem in affects:\n",
    "                affect_sent_dict[elem].append(0)\n",
    "        \n",
    "        if w in emo_dict:\n",
    "            for elem in emos:\n",
    "                try:\n",
    "                    emo_sent_dict[elem].append(float(emo_dict[w][elem]))\n",
    "                except Exception as e:\n",
    "                    emo_sent_dict[elem].append(0)\n",
    "        else:\n",
    "            for elem in emos:\n",
    "                emo_sent_dict[elem].append(0)\n",
    "            \n",
    "    vad_features    = []\n",
    "    affect_features = []\n",
    "    emo_features    = []\n",
    "    \n",
    "    for elem in vads:\n",
    "        val = np.mean(vad_sent_dict[elem])\n",
    "        if val== val:\n",
    "            vad_features.append(val)\n",
    "        else:\n",
    "            vad_features.append(0)\n",
    "            \n",
    "    for elem in affects:\n",
    "        val = np.mean(affect_sent_dict[elem])\n",
    "        if val== val:\n",
    "            affect_features.append(val)\n",
    "        else:\n",
    "            affect_features.append(0)\n",
    "    for elem in emos:\n",
    "        val = np.mean(emo_sent_dict[elem])\n",
    "        if val== val:\n",
    "            emo_features.append(val)\n",
    "        else:\n",
    "            emo_features.append(0)\n",
    "        \n",
    "    return vad_features, affect_features, emo_features\n",
    "\n",
    "def create_liwc(words):\n",
    "    category_tag={}\n",
    "    count=0\n",
    "    for category in liwc_categories:\n",
    "        category_tag[category]=0\n",
    "    category_tag['Other']=0\t\n",
    "\n",
    "    for word in words:\n",
    "        flag1=0\n",
    "        flag2=0\n",
    "\n",
    "        if word_categories_dict[word]!=[]:\n",
    "            flag1=1\n",
    "\n",
    "        for category in word_categories_dict[word]:\n",
    "            if category not in category_tag:\n",
    "                category_tag[category]=1\n",
    "            else:\n",
    "                category_tag[category]+=1\n",
    "\n",
    "        for substring in starred_word_categories_dict.keys():\n",
    "            if word.startswith(substring):\n",
    "                flag2=1\n",
    "                for category in starred_word_categories_dict[substring]:\n",
    "                    if category not in category_tag:\n",
    "                        category_tag[category]=1\n",
    "                    else:\n",
    "                        category_tag[category]+=1\n",
    "\n",
    "        if flag1==0 and flag2==0:\n",
    "            category_tag['Other']+=1\n",
    "        count+=1\n",
    "\n",
    "    if count>0:\n",
    "        for i in category_tag:\n",
    "            category_tag[i]=category_tag[i]/count\n",
    "\n",
    "    return category_tag\n",
    "\n",
    "vads=['Valence', 'Arousal', 'Dominance']\n",
    "affects=sorted(list({'joy', 'sadness', 'fear', 'anger'}))\n",
    "emos=sorted(list({'trust', 'fear', 'surprise', 'sadness', 'positive', 'joy', 'anger', 'negative', 'disgust', 'anticipation'}))\n",
    "liwc_categories=['Funct','Pronoun','Ppron','I','We','You','SheHe','They','Ipron','Article','Verbs','AuxVb','Past','Present','Future','Adverbs','Prep','Conj','Negate','Quant','Numbers','Swear','','Family','Friends','Humans','Affect','Posemo','Negemo','Anx','Anger','Sad','CogMech','Insight','Cause','Discrep','Tentat','Certain','Inhib','Incl','Excl','Percept','See','Hear','Feel','Body','Health','Sexual','Ingest','Relativ','Motion','Space','Time','Work','Achiev','Leisure','Home','Money','Relig','Death','Assent','Nonflu','Filler','Other']\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vaderSentiment\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[K     |████████████████████████████████| 125 kB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr0/home/rdutt/anaconda3/envs/med_ent/lib/python3.6/site-packages (from vaderSentiment) (2.23.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr0/home/rdutt/anaconda3/envs/med_ent/lib/python3.6/site-packages (from requests->vaderSentiment) (1.25.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr0/home/rdutt/anaconda3/envs/med_ent/lib/python3.6/site-packages (from requests->vaderSentiment) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr0/home/rdutt/anaconda3/envs/med_ent/lib/python3.6/site-packages (from requests->vaderSentiment) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr0/home/rdutt/anaconda3/envs/med_ent/lib/python3.6/site-packages (from requests->vaderSentiment) (2020.4.5.1)\n",
      "Installing collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n"
     ]
    }
   ],
   "source": [
    "! pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5956\n"
     ]
    }
   ],
   "source": [
    "print(len(conv_dict))\n",
    "\n",
    "ratios = sorted([conv_dict[conv]['ratio'] for conv in conv_dict])\n",
    "ratio_bar = np.median(ratios)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "only_words = r'\\b\\w+\\b'\n",
    "\n",
    "exception_arr = []\n",
    "\n",
    "def normalize_arr(arr):\n",
    "    if np.sum(arr)>0:\n",
    "        return arr/np.sum(arr)\n",
    "    else:\n",
    "        return np.zeros(len(arr))\n",
    "    \n",
    "def sentiment_analyze(text):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    vs = analyzer.polarity_scores(text)\n",
    "    return [vs['pos'],vs['neg'], vs['neu']]\n",
    "\n",
    "\n",
    "def create_conv(temp_df, train_flag = True):\n",
    "    try:\n",
    "        curr_id      = list(temp_df['Index'])[0]\n",
    "    except Exception as e:\n",
    "        import pdb; pdb.set_trace()\n",
    "    \n",
    "\n",
    "    convs      = []\n",
    "    conv       = []\n",
    "    max_utt_len  = 0\n",
    "    print(temp_df.columns)\n",
    "    print(len(temp_df), len(set(temp_df['Index'])))\n",
    "\n",
    "    max_utt_len = 0 \n",
    "    row_cnt     = 0\n",
    "    \n",
    "    for index, row in temp_df.iterrows():\n",
    "        row_cnt+=1\n",
    "        print('Done for {}'.format(row_cnt), end='\\r')\n",
    "        if row['Index']!= curr_id:\n",
    "            for elem in conv:\n",
    "                elem['bert-feat'].extend([0 for i in range(max_utt_len-len(elem['bert-feat']))])\n",
    "            if conv != []:\n",
    "                convs.append(conv)\n",
    "            conv = []\n",
    "            max_utt_len =0\n",
    "            curr_id = row['Index']\n",
    "            \n",
    "        utt_dict = {}\n",
    "        utt_dict['utterance'] = row['Text']\n",
    "        utt = normalizeString(row['Text'])\n",
    "        toks = tokenizer.convert_tokens_to_ids(tokenizer.tokenize('[CLS]')) +  tokenizer.convert_tokens_to_ids(tokenizer.tokenize(utt)) + tokenizer.convert_tokens_to_ids(tokenizer.tokenize('[SEP]'))\n",
    "        max_utt_len = max(max_utt_len, len(toks))\n",
    "        utt_dict['bert-feat'] = toks\n",
    "        utt_dict['fine_labels'] = row['fine_labels']\n",
    "        if row['fine_labels'] =='not-a-strategy':\n",
    "            utt_dict['coarse_labels']= row['fine_labels']\n",
    "        else:\n",
    "            utt_dict['coarse_labels']= row['fine_labels'].split('-')[1]\n",
    "\n",
    "        utt_dict['resistance_labels']= row['resistance_labels']\n",
    "        utt_dict['speaker']= row['User']\n",
    "\n",
    "        word_list= re.findall(only_words, row['Text'].lower().strip())\n",
    "        vad_feats, affect_feats, emo_feats = create_embeddings(word_list, vads, affects, emos)\n",
    "\n",
    "        for elem in vad_feats:\n",
    "            if elem!=elem:\n",
    "                import pdb; pdb.set_trace()\n",
    "\n",
    "        liwc_feats= create_liwc(word_list)\n",
    "\n",
    "        utt_dict['vad_features'] = vad_feats\n",
    "        utt_dict['affect_features'] = affect_feats\n",
    "        utt_dict['emo_features'] = emo_feats\n",
    "        utt_dict['liwc_features'] = [liwc_feats[i] for i in liwc_categories]\n",
    "\n",
    "        utt_dict['sentiments'] = sentiment_analyze(utt)\n",
    "        \n",
    "        if conv_dict[row['Index']]['ratio'] > ratio_bar:\n",
    "            utt_dict['ratio_bucket']  = 1 \n",
    "        else:\n",
    "            utt_dict['ratio_bucket']  = 0\n",
    "\n",
    "        conv.append(utt_dict)\n",
    "\n",
    "    for elem in conv:\n",
    "        elem['bert-feat'].extend([0 for i in range(max_utt_len-len(elem['bert-feat']))])\n",
    "\n",
    "    if conv != []:\n",
    "        convs.append(conv)\n",
    "\n",
    "    print(len(convs))\n",
    "    \n",
    "    return convs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Index', 'User', 'Text', 'fine_labels', 'Unnamed: 5',\n",
      "       'Unnamed: 6', 'resistance_labels'],\n",
      "      dtype='object')\n",
      "7582 562\n",
      "633e for 7582\n",
      "Index(['Unnamed: 0', 'Index', 'User', 'Text', 'fine_labels', 'Unnamed: 5',\n",
      "       'Unnamed: 6', 'resistance_labels'],\n",
      "      dtype='object')\n",
      "1969 141\n",
      "167e for 1969\n",
      "1969\n",
      "7582\n",
      "0.07719654647028949\n",
      "Index(['Unnamed: 0', 'Index', 'User', 'Text', 'fine_labels', 'Unnamed: 5',\n",
      "       'Unnamed: 6', 'resistance_labels'],\n",
      "      dtype='object')\n",
      "7532 562\n",
      "636e for 7532\n",
      "Index(['Unnamed: 0', 'Index', 'User', 'Text', 'fine_labels', 'Unnamed: 5',\n",
      "       'Unnamed: 6', 'resistance_labels'],\n",
      "      dtype='object')\n",
      "2019 141\n",
      "164e for 2019\n",
      "2019\n",
      "7532\n",
      "0.0633977216443784\n",
      "Index(['Unnamed: 0', 'Index', 'User', 'Text', 'fine_labels', 'Unnamed: 5',\n",
      "       'Unnamed: 6', 'resistance_labels'],\n",
      "      dtype='object')\n",
      "7656 562\n",
      "642e for 7656\n",
      "Index(['Unnamed: 0', 'Index', 'User', 'Text', 'fine_labels', 'Unnamed: 5',\n",
      "       'Unnamed: 6', 'resistance_labels'],\n",
      "      dtype='object')\n",
      "1895 141\n",
      "158e for 1895\n",
      "1895\n",
      "7656\n",
      "0.06965699208443271\n",
      "Index(['Unnamed: 0', 'Index', 'User', 'Text', 'fine_labels', 'Unnamed: 5',\n",
      "       'Unnamed: 6', 'resistance_labels'],\n",
      "      dtype='object')\n",
      "7694 563\n",
      "646e for 7694\n",
      "Index(['Unnamed: 0', 'Index', 'User', 'Text', 'fine_labels', 'Unnamed: 5',\n",
      "       'Unnamed: 6', 'resistance_labels'],\n",
      "      dtype='object')\n",
      "1857 140\n",
      "154e for 1857\n",
      "1857\n",
      "7694\n",
      "0.08831448572967152\n",
      "Index(['Unnamed: 0', 'Index', 'User', 'Text', 'fine_labels', 'Unnamed: 5',\n",
      "       'Unnamed: 6', 'resistance_labels'],\n",
      "      dtype='object')\n",
      "7740 563\n",
      "643e for 7740\n",
      "Index(['Unnamed: 0', 'Index', 'User', 'Text', 'fine_labels', 'Unnamed: 5',\n",
      "       'Unnamed: 6', 'resistance_labels'],\n",
      "      dtype='object')\n",
      "1811 140\n",
      "157e for 1811\n",
      "1811\n",
      "7740\n",
      "0.07730535615681944\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "for count in range(0,5):\n",
    "    print('count {}'.format(count), end ='\\r')\n",
    "    train_ids = train_ids_dict[count]\n",
    "    test_ids  = test_ids_dict[count]\n",
    "    \n",
    "    train= df.loc[df['Index'].isin(train_ids)]\n",
    "    conv_json = create_conv(train, True)\n",
    "    with open(DATA_PATH+'/higru_bert_data/train'+str(count)+'neg'+'.json','w') as handle:\n",
    "        json.dump(conv_json,handle, indent=4)\n",
    "    \n",
    "    test= df.loc[df['Index'].isin(test_ids)]\n",
    "    conv_json = create_conv(test, False)\n",
    "    with open(DATA_PATH+'/higru_bert_data/test'+str(count)+'neg'+'.json','w') as handle:\n",
    "        json.dump(conv_json,handle, indent=4)\n",
    "\n",
    "    train_sentences = []\n",
    "    test_sentences  = []\n",
    "\n",
    "    for index, row in train.iterrows():\n",
    "        train_sentences.append(row['Text'].lower().strip())\n",
    "\n",
    "    for index, row in test.iterrows():\n",
    "        test_sentences.append(row['Text'].lower().strip())\n",
    "\n",
    "    print(len(test))\n",
    "    print(len(train))\n",
    "\n",
    "    cnt=0\n",
    "    for elem in test_sentences:\n",
    "        if elem in train_sentences:\n",
    "            cnt+=1\n",
    "\n",
    "    print(cnt/len(test_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([utt['ratio_bucket'] for conv in conv_json for utt in conv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1513\n",
      "6287\n",
      "0.8288169200264376\n"
     ]
    }
   ],
   "source": [
    "train_sentences = []\n",
    "test_sentences  = []\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    train_sentences.append(row['Text'].lower().strip())\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    test_sentences.append(row['Text'].lower().strip())\n",
    "\n",
    "print(len(test))\n",
    "print(len(train))\n",
    "\n",
    "count=0\n",
    "for elem in test_sentences:\n",
    "    if elem in train_sentences:\n",
    "        count+=1\n",
    "\n",
    "print(count/len(test_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count 0\r",
      "10 10 0\n",
      "count 1\r",
      "10 10 0\n",
      "count 2\r",
      "10 10 0\n",
      "count 3\r",
      "10 10 0\n",
      "count 4\r",
      "10 10 0\n"
     ]
    }
   ],
   "source": [
    "for count in range(0,5):\n",
    "    print('count {}'.format(count), end ='\\r')\n",
    "    train_ids = train_ids_dict[count]\n",
    "    test_ids  = test_ids_dict[count]\n",
    "    \n",
    "    train= df.loc[df['B2'].isin(train_ids)]\n",
    "    train_labels = set(train['fine_labels'])\n",
    "    \n",
    "    test= df.loc[df['B2'].isin(test_ids)]\n",
    "    test_labels = set(test['fine_labels'])\n",
    "    \n",
    "    print(len(train_labels), len(test_labels), len(test_labels - train_labels))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vad_features', 'affect_features', 'emo_features', 'liwc_features', 'sentiments', 'face_acts', 'norm_er_strategies', 'norm_er_DAs', 'ee_DAs']\n"
     ]
    }
   ],
   "source": [
    "feature_dim_dict = {'vad_features': 3, 'affect_features': 4, 'emo_features': 10, 'liwc_features': 64, 'sentiments': 3, 'face_acts': 8, 'norm_er_strategies': 10, 'norm_er_DAs': 17, 'ee_DAs': 23, 'all': 3+4+10+64+3+8+10+17+23}\n",
    "\n",
    "feature_dim_arr  = [i for i in feature_dim_dict if i!='all']\n",
    "print(feature_dim_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
